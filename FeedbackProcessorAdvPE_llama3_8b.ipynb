{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90c1a03e-df10-497f-8642-dc3265d2ee93",
   "metadata": {},
   "source": [
    "# Setup "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93d73af-65f4-4627-9b38-fae747c78392",
   "metadata": {},
   "source": [
    "## import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acd33d0-02c9-44ee-83b6-162bd635bbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import pandas as pd\n",
    "import json\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain import PromptTemplate\n",
    "import re\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89681a99-e774-4d8f-b532-5badd57ef8b5",
   "metadata": {},
   "source": [
    "## import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de305f4-ebd1-43b4-8cba-63730ef1f16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "athenadata = open(\"Downloads/Athena_feedback.txt\", encoding='windows-1252').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c915ca9c-86b2-4893-b18f-3c1f45b49eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "UserID = []\n",
    "Message = []\n",
    "\n",
    "for i in range(0,len(athenadata)):\n",
    "    if i % 2 == 0:\n",
    "        UserID.append(athenadata[i])\n",
    "    elif i % 2 == 1:\n",
    "        Message.append(athenadata[i])\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93841192-00d8-4bab-a9ec-96602dbd34da",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUF_Df = pd.DataFrame({\n",
    "    'UserID':UserID,\n",
    "    'Message':Message\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf83b81b-33db-4b27-b7f7-54a06fa6c79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUF_Df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4642f885-9145-4b41-b4ea-c66f1621e984",
   "metadata": {},
   "source": [
    "## Select LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1877b2a-837c-402b-bb47-541e52df1d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = Ollama(base_url='http://localhost:11434',\n",
    "#              model=\"llama2\")\n",
    "# mistral_bot = Ollama(base_url='http://localhost:11434',\n",
    "#              model=\"mistral\")\n",
    "ActiveLLM = Ollama(base_url='http://localhost:11434',\n",
    "             model=\"llama3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225625ba-35ad-4649-9543-363a33392cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def useLLM(input, template):\n",
    "    \n",
    "    output = ActiveLLM(\n",
    "    template.format(\n",
    "        userfeedback=input\n",
    "        )\n",
    "    )\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455eb723-77b3-49df-82bc-ca753239a3c1",
   "metadata": {},
   "source": [
    "## Initialize prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28a97d3-d3d3-4b36-aa64-5675a969ecfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "UX_topic_prompt_SC = \"\"\"\n",
    "Role: You are in the role of a UX researcher evaluating user feedback to find what users like about our new software system. Those likes and dislikes will be eventually turned into design decisions.\n",
    "Our system is an AI system that helps user navigate a database of petroleum engineering documentation.\n",
    "\n",
    "Instructions:\n",
    "I will give you some text that is feedback from a user testing a new software system. \n",
    "This feedback may be long and cover multiple topics. In that case break down the response into the component topics and return only 1-4 main topics.\n",
    "Also, summarize those main topics so that each topic is concicse, and make sure that none of the main topics are redundant. write those main topics and an explanation of those topics in a list format like so: [\"main topic 1\": \"your explanation\", \"main topic 2\": \"your explanation\", \"main topic 3\": \"your explanation\"].\n",
    "Think through this process step by step.\n",
    "Then repeat this process five times so that you have a 5 lists of main topics with explanations. \n",
    "Then review the topics you have written and choose the topics that are the most consistent and not redundant with the prvooius topics and add one final list of these best and most representative topics.\n",
    "\n",
    "your final output should be a list of lists with 5 sets of main topics with explanation, and a final list of just the most consistent main topics with explanations for those topics.\n",
    "\n",
    "Do not stop to ask me if you should process or do anything else except complete the task of creating 5 sets of potential main topcs and a final set that you think best catprues what you did the firts 5 times.\n",
    "\n",
    "Here is an example:\n",
    "\n",
    "Example: \n",
    "    User Feedback: \"The search function was excellent, but the insight feature was poor\"\n",
    "    Output: [[\"search function: the users discuss the search function\", \"insight feature: the user said they didnt like the insights feature\"],\n",
    "            [\"search: the user seems focused on the search abilities of the system\", \"insight: the user was focused on giving feedback about the insight system\"],\n",
    "            [\"system\": the user mentions a system\", \"insight: the user commented on the insight feature\"],\n",
    "            [\"search: the user seems to discuss the excellency of search\", \"poor: the user said the system was poor\"],\n",
    "            [\"search: the user seems focused on the search abilities of the system\", \"insight: the user was focused on giving feedback about the insight system\"],\n",
    "            [\"search\": the user focused on the excellency of the search, \"insight: the user found the insights to be not useful\"]]\n",
    "\n",
    "User Feedback: {userfeedback}\n",
    "Output: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6dfb8df-4700-40c9-8402-ce38ab043cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_templateT = PromptTemplate(\n",
    "    input_variables=[\"userfeedback\"],\n",
    "    template=UX_topic_prompt_SC\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90327a0-140d-478d-87e3-6f356e4825fe",
   "metadata": {},
   "source": [
    "# use actually process data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36daec6a-7c86-48d4-aa17-0677cd0b11d6",
   "metadata": {},
   "source": [
    "## get initial topics\n",
    "notice that we processed just one message first because this is rather slow, \n",
    "so I recommend when you are adapting your prompt to try it on one message at a time first \n",
    "before running all of them as it take 30 minutes to an hour to run for everyone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc64b10-b026-4dc6-a8c7-ec70b4999ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUF_Dft1 = AUF_Df.iloc[0:1,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f687fbc-a31b-4320-b006-fa0eb289e9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUF_Dft1['Message'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e93cfc-4fc6-429b-9035-981879b1d9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUF_Dft1['Topics'] = AUF_Dft1['Message'].apply(useLLM, template=prompt_templateT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b293a324-10b6-4c70-bd53-97ca97aa0f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUF_Dft1['Topics'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7360c1d5-cfa4-44f5-9aa9-2c24485fc23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUF_Dft1['MainTopics'] = AUF_Dft1['Topics'].apply(lambda x: x.split('[')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561d0589-6768-47f7-8ed1-0fb947b2e990",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUF_Dft1['MainTopics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c690714-bf51-4055-aedb-28c9a4b8443f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d521ac92-eaba-4018-8ea9-38834a2e32ae",
   "metadata": {},
   "source": [
    "## do full df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad14f0d0-4112-4533-8d77-21bea4d35d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUF_Df['Topics'] = AUF_Df['Message'].apply(useLLM, template=prompt_templateT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d95272d-2fed-47a3-a081-76f1c4594a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUF_Df['Topics'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61138304-04e3-4695-bd59-f651ab19078c",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUF_Df['Topics'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cd0a63-71f2-4a9e-85ca-63c1ea75bd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUF_Df['MainTopics'] = AUF_Df['Topics'].apply(lambda x: x.split('[')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d2584e-100a-408a-819b-7018c543843d",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUF_Df['MainTopics'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cde51a-20b7-4dec-aa9d-aa7813e4cde4",
   "metadata": {},
   "source": [
    "## use LLM to try to trim total number of topics down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7674de1c-9f0d-47fd-bf2c-139d792a60d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "TopicSynthesizer_template = \"\"\"\n",
    "Role: You are in the role of a UX researcher working with other UX researchers evaluting user feedback to find what users like about our system. \n",
    "Our system is an AI system that helps user navigate a database of petroleum engineering documentation.\n",
    "We need to have a good understanding of what users like and dont like about our system so we can improve it.\n",
    "\n",
    "Instructions:\n",
    "Another UX researcher has already broken each of the user messages down into a few topics for each user. \n",
    "You will be given a list of sets of all of the topics that each user mentioned topics, and your job is to try to reduce all topics down to a few different major topics that reflect different parts of the system we should focus on. \n",
    "The set of major topics you generate should be about different parts of the system and not be redundant. You should try to provide only a few topics. \n",
    "For each topic you provide, also add an explanation of why you think that is a major theme and what you think we should do to address it.\n",
    "\n",
    "Topics List: {topicslist}\n",
    "Analysis: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087bc2fb-7dde-40a3-881c-dd19dcd60923",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_templateMTY = PromptTemplate(\n",
    "    input_variables=[\"topicslist\"],\n",
    "    template=TopicSynthesizer_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5108cf-0b4e-4688-900b-707b3c1b05da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def useLLM_topicSynthesizer(input, template):\n",
    "    \n",
    "    output = ActiveLLM(\n",
    "    template.format(\n",
    "        topicslist=input\n",
    "        )\n",
    "    )\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d48598-7f7d-45ed-9d2f-5bc7e858ef1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AUF_Df['MainTopics'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51148ba6-eae3-4ca2-9ebb-d8e8dcfaf187",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_list = AUF_Df['MainTopics'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2050a636-8657-4207-9e80-14c4c99bcd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Majortopics = useLLM_topicSynthesizer( topics_list ,template=prompt_templateMTY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b2ff7e-c6b8-41a2-b7c0-739774c9d94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Majortopics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9664cf-4ca7-4c67-8be5-0061d5f1978d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83dc520b-2881-44dd-af55-329f6ef239ee",
   "metadata": {},
   "source": [
    "# Additional Prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c509a7-57a6-4556-b93b-99803c5b430e",
   "metadata": {},
   "outputs": [],
   "source": [
    "UXSentiment_template = \"\"\"I will give you some text that is feedback from a user testing a new software system. Some of these responses are long and cover mutliple topics.\n",
    "Analyze the sentiment expressed in the user feedback and for each topic and provide classification of the overall sentiment of all the topics into 1 of 4 categories:\n",
    "\"positive sentiment\", \"negative sentiment\", \"neutral sentiment\", or \"mixed sentiment\". \n",
    "If the text seems like it was not about the software then say simply say \"NA\". \n",
    "first write your analysis, then classify the text, and then combine the two into a single list like so: [Analysis, Classification].\n",
    "Below are some examples to help you.\n",
    "\n",
    "Example 1: \n",
    "    User Feedback: \"The search function was excellent, but the insight feature was poor\"\n",
    "    Output:[\"the user like the search function but did not like the input function, and seemd to be equally stongly opinionated on both so this statement is of mixed sentiment\" , \"mixed sentiment\"]\n",
    "\n",
    "Example 2:\n",
    "    User Feedback: \"I really liked the layout of the user interface. The software was fast and responsive, and the functions did exactly what I expected.\"\n",
    "    Output: [\"The user expressed positive sentiment about all of the things they mentioned. this statement is postively sentiment\" , \"positive sentiment\"]\n",
    "\n",
    "Example 3:\n",
    "    User Feedback: \"The system was very difficult to use and not intuitive at all.\"\n",
    "    Output: [\"The user described the system as ndifficult and not intuitive. This statement is negatively sentiment.\" , \"negative sentiment\"]\n",
    "\n",
    "Example 4:\n",
    "    User Feedback: \"I like ice cream.\"\n",
    "    Analysis: [\"The statement does not seem to be about the software system.\" , \"NA\"]\n",
    "\n",
    "Example 5:\n",
    "    User Feedback: \"The software was fine and I finished my work.\"\n",
    "    Analysis: [\"The user did not express any strong sentiments about the system. This statement is of neutral sentiment.\" , \"neutral sentiment\"]\n",
    "\n",
    "User Feedback: {userfeedback}\n",
    "Analysis: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2508c3-c1e2-435b-8799-e7cb77323ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "UX_topic_prompt = \"\"\"\n",
    "Role: You are in the role of a UX researcher evaluting user feedback to find what users like about our system. Those likes and displikes will be eventually turned into design decisions.\n",
    "Our system is an AI system that helps user navigate a database of petroleum engineering documentation.\n",
    "\n",
    "Instructions:\n",
    "I will give you some text that is feedback from a user testing a new software system. \n",
    "This feedback may be long and cover mutliple topics. In that case break down the response into the component topics and return only 1-4 main topics.\n",
    "Also, summarize those main topics so that each one is only one or two words long, and make sure that none of the main topics are redundant.\n",
    "Think through this process step by step.\n",
    "Finally, Once you have determined a set of main topics, return those main topics in a list form like so: [\"main topic 1\", \"main topic 2\", \"main topic 3\"]. \n",
    "Do not return the users original feedback or any additional explanation.\n",
    "\n",
    "Here are two examples:\n",
    "\n",
    "Example1: \n",
    "    User Feedback: \"The search function was excellent, but the insight feature was poor\"\n",
    "    Output: [\"search function\", \"insight feature\"]\n",
    "\n",
    "Example 2:\n",
    "    User Feedback: \"The system was very difficult to use and not intuitive at all.\"\n",
    "    Output: [\"the system\"]\n",
    "\n",
    "User Feedback: {userfeedback}\n",
    "Output: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c1affd-7b7c-4b86-88d5-97834af54ea2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529e9850-a2c2-4533-b840-7ee4dcc4c681",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f471da9d-dabd-44e0-8fd8-adcd6e72c1fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab2b880-0bd1-4fd0-aedc-7922b4835584",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1fc20282-ee86-4395-8d72-0528f65e67eb",
   "metadata": {},
   "source": [
    "# Scraps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20392d15-498c-4b84-86cd-9c6ee7ac7ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUF_Df['MainTopics'] = AUF_Df['Topics'].apply(lambda x: str.split(str.split(x, 'Final Output:')[-1].strip(' []\\\"').replace('\"', '').replace(' ', ''),','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27262c9d-baf1-4539-933b-eeb0b6b941ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "str.split(str.split(AUF_Df['Topics'][2], 'Final Output:')[-1].strip(' []\\\"').replace('\"', '').replace(' ', ''),',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fae2db2-1983-4d24-b85a-1099008981a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ast.literal_eval(AUF_Df['Topics'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9424ee-5fca-40ea-8141-08cdd15d6392",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate(\n",
    "    template=UXSentiment_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9786b28a-c2a7-46f4-91dc-70675aa50e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUF_Dft3 = AUF_Df.iloc[1:3,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0872ae9b-4649-4bd7-8c6e-b255d53fce64",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUF_Dft3['Topics'] = AUF_Dft3['Message'].apply(usemistral, template=prompt_templateT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad89f1fb-fa66-4372-bcde-df5af41d5560",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUF_Dft3['Topics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1104139-375b-4578-ab96-bd2af6d01dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "UF_Df['Analysis' ,'Valence'] = UF_Df['Message'].apply(usemistral, template=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1003274f-a845-4b1a-a225-7a97bc7073f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "UF_Df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d951dfdd-65e2-4450-bef5-0835405d84cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "UF_Df.iloc[2,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e302821-38a1-4044-a8b1-05688dc03e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "UF_Df.iloc[2,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec71b57-8b32-4e9c-953c-b8834395bcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UF_Df['Analysis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67faf053-ffd4-40c7-a2e3-bd55b08ab6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUF_Dft = AUF_Df.iloc[:1,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985d4461-572a-480b-a01c-df2452100c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUF_Dft['Analysis' ,'Valence'] = AUF_Dft['Message'].apply(usemistral, template=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1171f6ad-76df-4713-93c1-b473e17b6113",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUF_Dft.iloc[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326d5abd-7a85-4b43-9609-02af066d9e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUF_Dft.iloc[0,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d510018-10c4-4511-b1d9-d8fcbeb30080",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUF_Dft2 = AUF_Df.iloc[:2,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ab3a0c-7733-4e52-bf14-c3e6e7230c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUF_Dft2['Topics'] = AUF_Dft['Message'].apply(usemistral, template=prompt_templateT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49418ccc-1f95-4974-b44e-5b87382d9621",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUF_Dft2['Message'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af7f337-4465-4722-a133-7eb7e54f2842",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUF_Dft2['Topics'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded7ef54-19ed-42b5-b697-92d22d720df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUF_Dft2['Message'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae95f6e9-f65b-4a84-a63c-3504eaf15036",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUF_Dft2['Topics'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1181375f-2a26-4db2-b217-a34fffc10477",
   "metadata": {},
   "outputs": [],
   "source": [
    "UF_Df['Valence'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c8af67-e95b-436e-9d27-ee388b73a123",
   "metadata": {},
   "outputs": [],
   "source": [
    "UF_Df['Message'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e50b65c-e8de-4358-a708-bc2ceb59f6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "UF_Df['Message'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e0692e-6848-4b2e-af57-1c0bea23539e",
   "metadata": {},
   "outputs": [],
   "source": [
    "UF_Df['Message'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fbd76f-7e2d-4d53-a99c-a68297912375",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a344671d-7559-4571-803e-ebffe62221a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef5e6ce-a220-4620-9702-e691914675f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mistral_bot(\n",
    "    prompt_template.format(\n",
    "        userfeedback=\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668165d4-ca76-44b0-b52c-746b7a9b6e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(llm('Hello, how are you?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b19db92-659e-43b8-8b5f-4aba6e4f9797",
   "metadata": {},
   "outputs": [],
   "source": [
    "teststore = llm(\"say testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d38cfca-536b-464d-a050-5f323b1d1232",
   "metadata": {},
   "outputs": [],
   "source": [
    "mistral_bot = Ollama(base_url='http://localhost:11434',\n",
    "             model=\"mistral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6cbd82-2fac-4b6c-80fb-48766a88c7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mistral_bot(\"say I am mistral\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1514bb4a-0241-4218-8505-d4a7fc675bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mistral_bot({\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"why is the sky blue?\"\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97fcbb3-9239-4db1-8b68-6d766a903c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Answer the question based on the context below. If the\n",
    "question cannot be answered using the information provided answer\n",
    "with \"I don't know\".\n",
    "\n",
    "Context: {previous_context}\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Answer: \"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"query\",\"previous_context\"],\n",
    "    template=template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342c9149-6930-49d5-b79f-16c9706e4e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    prompt_template.format(\n",
    "        query=\"Who was the first president of the united states?\",\n",
    "        previous_context=\"\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486e1026-619a-4fce-8bde-d27280cdb856",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66890773-5ed5-4298-b9b9-532039eb80a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "myquery = \"Who was the first president of the united states?\"\n",
    "current_response = mistral_bot(\n",
    "    prompt_template.format(\n",
    "        query=myquery,\n",
    "        previous_context = chat_history\n",
    "        \n",
    "    )\n",
    ")\n",
    "chat_history += \"User Question:\" + myquery + \"\\n\"\n",
    "chat_history += \"LLM Response:\" + current_response + \"\\n\"\n",
    "print(current_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d02dfc-1a88-4c32-a571-534e2f717321",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    prompt_template.format(\n",
    "        query=\"Did he write lord of the rings?\",\n",
    "        previous_context=chat_history\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66b45cb-4572-4b32-8c5f-584286f5cdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "myquery = \"What dog was in the sandlot movie?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbaba49a-8bfe-46b1-8741-9afb3a0ce53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    prompt_template.format(\n",
    "        query=\"myquery\",\n",
    "        previous_context=chat_history\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c6ebb9-067f-47ff-9e60-a6368f159386",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(chat_history) > 3000:\n",
    "    print(\"youre are running out of tokens, just a heads up.\")\n",
    "current_response = mistral_bot(\n",
    "    prompt_template.format(\n",
    "        query=myquery,\n",
    "        previous_context = chat_history\n",
    "        \n",
    "    )\n",
    ")\n",
    "chat_history += myquery\n",
    "chat_history += current_response\n",
    "print(current_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b298f1-02c7-4368-b61d-3eb165ccf5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# myquery = input()\n",
    "# if len(chat_history) > 3000:\n",
    "#     print(\"youre are running out of tokens, just a heads up.\")\n",
    "# current_response = mistral_bot(\n",
    "#     prompt_template.format(\n",
    "#         query=myquery,\n",
    "#         previous_context = chat_history\n",
    "        \n",
    "#     )\n",
    "# )\n",
    "# chat_history += myquery\n",
    "# chat_history += current_response\n",
    "# print(current_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6f41d2-b486-4d27-a91c-f4248956541b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLd User sent template\n",
    "#UXSentiment_template = \"\"\"I will give you some text that is feedback from a user testing a new software system. \n",
    "# Analyze the emotional valence expressed in the user feedback and then classify the user feedback based on the emotional valence of the text into 1 of 4 categories:\n",
    "# \"positive valence\", \"negative valence\", \"neutral valence\", or of \"mixed valence\". \n",
    "# If the text seems like it was not about the software then say simply say \"NA\". \n",
    "# first write your analysis, then classify the text, and then combine the two into a single list like so: [Analysis, Classification].\n",
    "# Below are some examples to help you.\n",
    "\n",
    "# Example 1: \n",
    "#     User Feedback: \"The search function was excellent, but the insight feature was poor\"\n",
    "#     Output:[\"the user like the search function but did not like the input function, and seemd to be equally stongly opinionated on both so this statement is of mixed valence\", \"mixed valence\"]\n",
    "#     Analysis: \"mixed valence\"\n",
    "\n",
    "# Example 2:\n",
    "#     User Feedback: \"I really liked the layout of the user interface. The software was fast and responsive, and the fucntions did exactly what I expected.\"\n",
    "#     Analysis: \"positive valence\"\n",
    "\n",
    "# Example 3:\n",
    "#     User Feedback: \"The system was very difficult to use and not intuitive at all.\"\n",
    "#     Analysis: \"negative valence\"\n",
    "\n",
    "# Example 4:\n",
    "#     User Feedback: \"I like cookies.\"\n",
    "#     Analysis: \"NA\"\n",
    "\n",
    "# Example 5:\n",
    "#     User Feedback: \"The software was fine and I finished my work.\"\n",
    "#     Analysis: \"neutral valence\"\n",
    "\n",
    "# User Feedback: {userfeedback}\n",
    "# Analysis: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3b117d-bb98-47d2-aba0-3ac84bb3cb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UserID = []\n",
    "# System = []\n",
    "# Message = []\n",
    "\n",
    "# for i in range(0,len(filelines)):\n",
    "#     if filelines[i] == '':\n",
    "#         continue\n",
    "#     elif filelines[i][-8:] == 'GMT 2023' :\n",
    "#         UserID.append(int(filelines[i].split(' ')[0].split('-')[1]))\n",
    "#         System.append(filelines[i].split(' ')[2][0])\n",
    "#     else:\n",
    "#         Message.append(filelines[i])\n",
    "        \n",
    "                      \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938478f8-f5c3-4b3b-8e4b-98f3fc0d7d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ux sentiment template 2\n",
    "# UXSentiment_template = \"\"\"I will give you some text that is feedback from a user testing a new software system. \n",
    "# Analyze the emotional valence expressed in the user feedback and then classify the user feedback based on the emotional valence of the text into 1 of 4 categories:\n",
    "# \"positive valence\", \"negative valence\", \"neutral valence\", or \"mixed valence\". \n",
    "# If the text seems like it was not about the software then say simply say \"NA\". \n",
    "# first write your analysis, then classify the text, and then combine the two into a single list like so: [Analysis, Classification].\n",
    "# Below are some examples to help you.\n",
    "\n",
    "# Example 1: \n",
    "#     User Feedback: \"The search function was excellent, but the insight feature was poor\"\n",
    "#     Output:[\"the user like the search function but did not like the input function, and seemd to be equally stongly opinionated on both so this statement is of mixed valence\" , \"mixed valence\"]\n",
    "\n",
    "# Example 2:\n",
    "#     User Feedback: \"I really liked the layout of the user interface. The software was fast and responsive, and the fucntions did exactly what I expected.\"\n",
    "#     Output: [\"The user expressed positive sentiment about all of the things they mentioned. this statement is postively valenced\" , \"positive valence\"]\n",
    "\n",
    "# Example 3:\n",
    "#     User Feedback: \"The system was very difficult to use and not intuitive at all.\"\n",
    "#     Output: [\"The user described the system as ndifficult and not intuitive. This statement is negatively valenced.\" , \"negative valence\"]\n",
    "\n",
    "# Example 4:\n",
    "#     User Feedback: \"I like ice cream.\"\n",
    "#     Analysis: [\"The statement does not seem to be about the software system.\" , \"NA\"]\n",
    "\n",
    "# Example 5:\n",
    "#     User Feedback: \"The software was fine and I finished my work.\"\n",
    "#     Analysis: [\"The user did not express any strong sentiments about the system. This statement is of neutral valence.\" , \"neutral valence\"]\n",
    "\n",
    "# User Feedback: {userfeedback}\n",
    "# Analysis: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cd80ab-68d8-4979-8734-1568ec9ef17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "UF_Df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455dd75d-e798-451c-86e5-e231af056adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "UserID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f80a65-6289-4ed0-ad81-b9f67618bd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,15):\n",
    "    if i % 3 == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401f2e3e-9640-45e2-b1d8-316268f21a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "UserID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a514e0b7-355a-4bb6-aa90-f9574fc531a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "filelines[0].split(' ')[0].split('-')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5295c94b-0aae-4a59-a133-eaf2d10f8c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filelines[0].split(' ')[2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c024c64d-5df4-47cb-a3b5-dc5661b99096",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c012fa4f-062d-4f4b-8da0-8007758f2d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()\n",
    "# dir_path = os.path.dirname(os.path.realpath(__file__))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898461c2-6bee-4773-881a-70683f32c269",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = os.path.dirname(os.path.realpath(\"FAKE_AthenUserFeedback.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a129d1f-22b4-4c07-ae25-e02c84a572ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.load(\"Downloads/FAKE_AthenUserFeedback.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4f0f28-2648-498a-b761-f585306478a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening JSON file\n",
    "f = open('Downloads/FAKE_AthenUserFeedback.txt')\n",
    " \n",
    "# returns JSON object as \n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    " \n",
    "# Iterating through the json\n",
    "# list\n",
    "for i in data['emp_details']:\n",
    "    print(i)\n",
    " \n",
    "# Closing file\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1fc567-efa5-450e-9d54-ff4a52f6b9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# FormLLM_Template = \"\"\"\n",
    "\n",
    "# Instructions: {}\n",
    "\n",
    "# Context: {}\n",
    "\n",
    "# User Input: {}\n",
    "\n",
    "# Output: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a24ef1b-78c5-43f8-9efd-d5a42933d97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TwoKilo_Template = \"\"\"\n",
    "\n",
    "# Instructions: {\n",
    "# You are a form checker, your job is to ...\n",
    "# Here are the instructions for how to fill out a 2 Kilo form. \n",
    "# Here are detail about how the information in the for is used.\n",
    "\n",
    "# Here are some examples of good an bad responses to certain fields of the 2 kilo form\n",
    "\n",
    "# Example1\n",
    "\n",
    "# Example 2\n",
    "\n",
    "# Example 3\n",
    "# }\n",
    "\n",
    "# Context: {Here is information about the role that the current sailor serves,\n",
    "# Here is infromatoin about the ship and systems that they work on, and \n",
    "# Here is infromatino about the jargon or slang associated with that role\n",
    "# Here is the infromation the sailor has already put into the form}\n",
    "\n",
    "# User Input: {The field the user is currently filling is ...\n",
    "\n",
    "# here is the users input to the field\n",
    "# }\n",
    "\n",
    "# Output: \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
