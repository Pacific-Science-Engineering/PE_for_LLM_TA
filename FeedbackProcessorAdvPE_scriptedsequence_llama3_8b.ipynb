{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90c1a03e-df10-497f-8642-dc3265d2ee93",
   "metadata": {},
   "source": [
    "# Setup "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93d73af-65f4-4627-9b38-fae747c78392",
   "metadata": {},
   "source": [
    "## import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acd33d0-02c9-44ee-83b6-162bd635bbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import pandas as pd\n",
    "import json\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain import PromptTemplate\n",
    "import re\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89681a99-e774-4d8f-b532-5badd57ef8b5",
   "metadata": {},
   "source": [
    "## import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de305f4-ebd1-43b4-8cba-63730ef1f16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "athenadata = open(\"Downloads/Athena_feedback.txt\", encoding='windows-1252').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c915ca9c-86b2-4893-b18f-3c1f45b49eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "UserID = []\n",
    "Message = []\n",
    "\n",
    "for i in range(0,len(athenadata)):\n",
    "    if i % 2 == 0:\n",
    "        UserID.append(athenadata[i])\n",
    "    elif i % 2 == 1:\n",
    "        Message.append(athenadata[i])\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93841192-00d8-4bab-a9ec-96602dbd34da",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUF_Df = pd.DataFrame({\n",
    "    'UserID':UserID,\n",
    "    'Message':Message\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf83b81b-33db-4b27-b7f7-54a06fa6c79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUF_Df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4642f885-9145-4b41-b4ea-c66f1621e984",
   "metadata": {},
   "source": [
    "## Select LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1877b2a-837c-402b-bb47-541e52df1d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = Ollama(base_url='http://localhost:11434',\n",
    "#              model=\"llama2\")\n",
    "# mistral_bot = Ollama(base_url='http://localhost:11434',\n",
    "#              model=\"mistral\")\n",
    "ActiveLLM = Ollama(base_url='http://localhost:11434',\n",
    "             model=\"llama3.1\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455eb723-77b3-49df-82bc-ca753239a3c1",
   "metadata": {},
   "source": [
    "## Initialize prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28a97d3-d3d3-4b36-aa64-5675a969ecfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "UX_metathemeUXR_prompt = \"\"\"\n",
    "Role: You are in the role of a UX researcher evaluating user feedback to find what users like about our new software system. Those likes and dislikes will be eventually turned into design decisions.\n",
    "Our system is an AI system that helps user navigate a database of petroleum engineering documentation.\n",
    "\n",
    "Instructions:\n",
    "You will be given a piece of userfeedback, and notes on what has been in the user feedback data so far.  Analyze the piece of user feedback in the context of the notes. This feedback may be long and cover 1 -4 main topics. Write a new summary of what has been seen so far based on the notes and the current piece of feedback. The new summary should contain the themes that have been seen so far and how much evidence there is for theme, and any new themes from the current piece of feedback.\n",
    "For example if the notes say that “users find the search function frustrating” and the piece of feedback you are analyzing says “search does not work properly” then the new notes you write down should capture how often you are finding evidence for the theme of frustration with the search function.  \n",
    "Try to keep the themes limited to 1-7 important themes. the themes should be concise and not redundant. Refactor the themes as needed as you gain more informaiton in the notes section.\n",
    "\n",
    "Example:\n",
    "\tExample Notes: So far we have analyzed 6 pieces of user feedback. And we have found that users are finding the writing function to be poor (five times), and the drawing function to be excellent (two times)\n",
    "\n",
    "\tExample user feedback:\n",
    "\t\tThe drawing function is excellent. The video function is excellent.\n",
    "\t\n",
    "\tExample Output:\n",
    "\t\tSo far we have analyzed 7 pieces of user feedback. And we have found that users are finding the writing function to be poor (5 times), and the drawing function to be excellent (3 times). And the video function is also excellent (1 time).\n",
    "\n",
    "Notes: {notes}\n",
    "\n",
    "User feedback: {userfeedback}\n",
    "\n",
    "Output: \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6dfb8df-4700-40c9-8402-ce38ab043cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_templateRolling = PromptTemplate(\n",
    "    input_variables=[\"notes\",\"userfeedback\"],\n",
    "    template=UX_metathemeUXR_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264117e4-c1ca-415b-85ec-3a9f19a0371c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_rollingtopicanalyzerLLM(input1, input2, template):\n",
    "\n",
    "    # print(template.format(userfeedback=input))\n",
    "    \n",
    "    output = ActiveLLM(\n",
    "    template.format(\n",
    "        notes=input1,\n",
    "        userfeedback=input2\n",
    "        )\n",
    "    )\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90327a0-140d-478d-87e3-6f356e4825fe",
   "metadata": {},
   "source": [
    "# use actually process data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36daec6a-7c86-48d4-aa17-0677cd0b11d6",
   "metadata": {},
   "source": [
    "## get initial topics\n",
    "notice that we processed just one message first because this is rather slow, \n",
    "so I recommend when you are adapting your prompt to try it on one message at a time first \n",
    "before running all of them as it take 30 minutes to an hour to run for everyone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc64b10-b026-4dc6-a8c7-ec70b4999ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUF_Dft1 = AUF_Df.iloc[0:2,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f687fbc-a31b-4320-b006-fa0eb289e9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUF_Dft1['Message'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f75c7d-0052-4e18-bd58-b6cb4bc9a419",
   "metadata": {},
   "outputs": [],
   "source": [
    "Notes = \"no notes yet\"\n",
    "for i in range(0, len(AUF_Dft1)):\n",
    "    Notes = use_rollingtopicanalyzerLLM(input1=Notes,input2=AUF_Dft1['Message'][i], template=prompt_templateRolling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee042bae-0cd8-4c93-b28e-bf8ce568f61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68af72b4-18df-4adf-9daf-73d267e62493",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2873f588-9a0f-4f82-8f3a-8564d27269c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Notes = \"no notes yet\"\n",
    "for i in range(0, len(AUF_Df)):\n",
    "    Notes = use_rollingtopicanalyzerLLM(input1=Notes,input2=AUF_Df['Message'][i], template=prompt_templateRolling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda92ef0-2f2a-4fae-9561-bb45680d380a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917648ab-71f1-4276-8119-531183cdc35a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944c893a-4b0a-43e7-8140-91ed39d19cfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e222e410-973c-4f15-b066-90f9a784a07e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38a3809-d4ff-4c22-8c43-8115e3ccebdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424a26fe-7716-4444-af43-866fbf647769",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4278ede0-bbfb-4504-8be3-640815f38153",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5309ab96-b866-4375-acc7-b4b99f62ddd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2277a75-e5de-4428-b17a-a8f1f2d7efba",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUF_Dft1['Topics1'] = AUF_Dft1['Message'].apply(use_topicanalyzerLLM, template=prompt_templateT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbab8eb-3cbe-4e96-9b99-4fd27ad56b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUF_Dft1['Topics1'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e93cfc-4fc6-429b-9035-981879b1d9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUF_Dft1['Topics1'] = AUF_Dft1['Message'].apply(use_topicanalyzerLLM, template=prompt_templateT)\n",
    "AUF_Dft1['Topics2'] = AUF_Dft1['Message'].apply(use_topicanalyzerLLM, template=prompt_templateT)\n",
    "AUF_Dft1['Topics3'] = AUF_Dft1['Message'].apply(use_topicanalyzerLLM, template=prompt_templateT)\n",
    "AUF_Dft1['Topics4'] = AUF_Dft1['Message'].apply(use_topicanalyzerLLM, template=prompt_templateT)\n",
    "AUF_Dft1['Topics5'] = AUF_Dft1['Message'].apply(use_topicanalyzerLLM, template=prompt_templateT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f7b406-e18b-498e-b98d-d6b18a102463",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUF_Dft1['combinedTopics'] = 'Researcher 1 :' + AUF_Dft1['Topics1'].astype(str) + 'Researcher 2:' + AUF_Dft1['Topics2'].astype(str) + 'Researcher 3:' + AUF_Dft1['Topics3'].astype(str) + 'Researcher 4:' + AUF_Dft1['Topics4'].astype(str) + 'Researcher 5:' + AUF_Dft1['Topics5'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1437584-9306-40f8-8243-3c8445480c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUF_Dft1['combinedTopics'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa5fb7f-3f21-4c43-83a2-66c2b6b99c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUF_Dft1['finalTopics'] = AUF_Dft1['combinedTopics'].apply(use_scLLM, template=prompt_templateSC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b293a324-10b6-4c70-bd53-97ca97aa0f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUF_Dft1['combinedTopics'] = 'Researcher 1 :' + AUF_Dft1['Topics1'].astype(str) + 'Researcher 2:' + AUF_Dft1['Topics2'].astype(str) + 'Researcher 3:' + AUF_Dft1['Topics3'].astype(str) + 'Researcher 4:' + AUF_Dft1['Topics4'].astype(str) + 'Researcher 5:' + AUF_Dft1['Topics5'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7360c1d5-cfa4-44f5-9aa9-2c24485fc23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_list_test = AUF_Dft1['finalTopics'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561d0589-6768-47f7-8ed1-0fb947b2e990",
   "metadata": {},
   "outputs": [],
   "source": [
    "Majortopics_test = useLLM_topicSynthesizer( topics_list_test ,template=prompt_templateMTY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c690714-bf51-4055-aedb-28c9a4b8443f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Majortopics_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d521ac92-eaba-4018-8ea9-38834a2e32ae",
   "metadata": {},
   "source": [
    "## do full df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad14f0d0-4112-4533-8d77-21bea4d35d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUF_Df['Topics1'] = AUF_Df['Message'].apply(use_topicanalyzerLLM, template=prompt_templateT)\n",
    "AUF_Df['Topics2'] = AUF_Df['Message'].apply(use_topicanalyzerLLM, template=prompt_templateT)\n",
    "AUF_Df['Topics3'] = AUF_Df['Message'].apply(use_topicanalyzerLLM, template=prompt_templateT)\n",
    "AUF_Df['Topics4'] = AUF_Df['Message'].apply(use_topicanalyzerLLM, template=prompt_templateT)\n",
    "AUF_Df['Topics5'] = AUF_Df['Message'].apply(use_topicanalyzerLLM, template=prompt_templateT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d95272d-2fed-47a3-a081-76f1c4594a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUF_Df['combinedTopics'] = 'Researcher 1 :' + AUF_Df['Topics1'].astype(str) + 'Researcher 2:' + AUF_Df['Topics2'].astype(str) + 'Researcher 3:' + AUF_Df['Topics3'].astype(str) + 'Researcher 4:' + AUF_Df['Topics4'].astype(str) + 'Researcher 5:' + AUF_Df['Topics5'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61138304-04e3-4695-bd59-f651ab19078c",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUF_Df['finalTopics'] = AUF_Df['combinedTopics'].apply(use_scLLM, template=prompt_templateSC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e508e7b2-c984-4c6e-ab24-817000d8b313",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_list = []\n",
    "for i  in range(0, len(AUF_Df), 10):\n",
    "    topics_list.append(\" \".join(AUF_Df['finalTopics'][i:i+10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4012dc3c-f7f0-4ff0-9ccd-de7f9ec4c69a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "topics_condensed = []\n",
    "for x in topics_list:\n",
    "    topics_condensed.append(useLLM_topicSynthesizer( x ,template=prompt_templateMTY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0479a828-a0b7-459c-94d6-bb8e8dcb4e3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Majortopics = useLLM_topicSynthesizer( \" \".join(topics_condensed) ,template=prompt_templateMTY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b80b37-5348-46b0-af22-5fb16512094a",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_list = AUF_Df['finalTopics'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65072e7-c873-45e6-94b6-66f622d1def1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# topics_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809b2c3b-a5ec-4348-9d8f-d173ddc6de91",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(topics_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf93d67-6b2d-4702-9015-afd6df1dfacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(\" \".join(topics_list))/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d2584e-100a-408a-819b-7018c543843d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Majortopics = useLLM_topicSynthesizer( topics_list ,template=prompt_templateMTY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bfd5ea-c00c-4052-bf2b-570e9bc13908",
   "metadata": {},
   "outputs": [],
   "source": [
    "Majortopics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64137c99-a41e-42ea-8115-88a985a982de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42ba2a1-3824-4508-8519-3fa4f3cc38df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adc9a6b-0173-4532-84ae-0df4fd0da9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUF_Df['finalTopics2'] = AUF_Df['combinedTopics'].apply(use_scLLM, template=prompt_templateSC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97edb55-5418-4564-b058-7243d6413b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_list2 = []\n",
    "for i  in range(0, len(AUF_Df), 10):\n",
    "    topics_list2.append(\" \".join(AUF_Df['finalTopics2'][i:i+10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75eff252-5fc9-47d7-919b-10c9b17da29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_condensed2 = []\n",
    "for x in topics_list2:\n",
    "    topics_condensed2.append(use_summLLM( x ,template=prompt_templateSumm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4830c199-da86-4f32-b4a8-0b6cce2a87b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Majortopics2 = useLLM_topicSynthesizer( \" \".join(topics_condensed2) ,template=prompt_templateMTY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542f783f-e117-4c47-b09a-1c02f382ea33",
   "metadata": {},
   "outputs": [],
   "source": [
    "Majortopics2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f9bb3b-3bcf-4a1c-abc1-eb2e1e9158ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d70c09-f301-4248-84ef-e449b43049de",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_condensed2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cde51a-20b7-4dec-aa9d-aa7813e4cde4",
   "metadata": {},
   "source": [
    "## use LLM to try to trim total number of topics down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7674de1c-9f0d-47fd-bf2c-139d792a60d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "TopicSynthesizer_template = \"\"\"\n",
    "Role: You are in the role of a UX researcher working with other UX researchers evaluting user feedback to find what users like about our system. \n",
    "Our system is an AI system that helps user navigate a database of petroleum engineering documentation.\n",
    "We need to have a good understanding of what users like and dont like about our system so we can improve it.\n",
    "\n",
    "Instructions:\n",
    "Another UX researcher has already broken each of the user messages down into a few topics for each user. \n",
    "You will be given a list of sets of all of the topics that each user mentioned topics, and your job is to try to reduce all topics down to a few different major topics that reflect different parts of the system we should focus on. \n",
    "The set of major topics you generate should be about different parts of the system and not be redundant. You should try to provide only a few topics. \n",
    "For each topic you provide, also add an explanation of why you think that is a major theme and what you think we should do to address it.\n",
    "\n",
    "Topics List: {topicslist}\n",
    "Analysis: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087bc2fb-7dde-40a3-881c-dd19dcd60923",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_templateMTY = PromptTemplate(\n",
    "    input_variables=[\"topicslist\"],\n",
    "    template=TopicSynthesizer_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5108cf-0b4e-4688-900b-707b3c1b05da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def useLLM_topicSynthesizer(input, template):\n",
    "\n",
    "    # print(template.format(topicslist = input))\n",
    "    \n",
    "    output = ActiveLLM(\n",
    "    template.format(\n",
    "        topicslist=input\n",
    "        )\n",
    "    )\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d48598-7f7d-45ed-9d2f-5bc7e858ef1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AUF_Df['MainTopics'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51148ba6-eae3-4ca2-9ebb-d8e8dcfaf187",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_list = AUF_Df['finalTopics'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2050a636-8657-4207-9e80-14c4c99bcd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Majortopics = useLLM_topicSynthesizer( topics_list ,template=prompt_templateMTY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b2ff7e-c6b8-41a2-b7c0-739774c9d94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Majortopics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9664cf-4ca7-4c67-8be5-0061d5f1978d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83dc520b-2881-44dd-af55-329f6ef239ee",
   "metadata": {},
   "source": [
    "# Additional Prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c509a7-57a6-4556-b93b-99803c5b430e",
   "metadata": {},
   "outputs": [],
   "source": [
    "UXSentiment_template = \"\"\"I will give you some text that is feedback from a user testing a new software system. Some of these responses are long and cover mutliple topics.\n",
    "Analyze the sentiment expressed in the user feedback and for each topic and provide classification of the overall sentiment of all the topics into 1 of 4 categories:\n",
    "\"positive sentiment\", \"negative sentiment\", \"neutral sentiment\", or \"mixed sentiment\". \n",
    "If the text seems like it was not about the software then say simply say \"NA\". \n",
    "first write your analysis, then classify the text, and then combine the two into a single list like so: [Analysis, Classification].\n",
    "Below are some examples to help you.\n",
    "\n",
    "Example 1: \n",
    "    User Feedback: \"The search function was excellent, but the insight feature was poor\"\n",
    "    Output:[\"the user like the search function but did not like the input function, and seemd to be equally stongly opinionated on both so this statement is of mixed sentiment\" , \"mixed sentiment\"]\n",
    "\n",
    "Example 2:\n",
    "    User Feedback: \"I really liked the layout of the user interface. The software was fast and responsive, and the functions did exactly what I expected.\"\n",
    "    Output: [\"The user expressed positive sentiment about all of the things they mentioned. this statement is postively sentiment\" , \"positive sentiment\"]\n",
    "\n",
    "Example 3:\n",
    "    User Feedback: \"The system was very difficult to use and not intuitive at all.\"\n",
    "    Output: [\"The user described the system as ndifficult and not intuitive. This statement is negatively sentiment.\" , \"negative sentiment\"]\n",
    "\n",
    "Example 4:\n",
    "    User Feedback: \"I like ice cream.\"\n",
    "    Analysis: [\"The statement does not seem to be about the software system.\" , \"NA\"]\n",
    "\n",
    "Example 5:\n",
    "    User Feedback: \"The software was fine and I finished my work.\"\n",
    "    Analysis: [\"The user did not express any strong sentiments about the system. This statement is of neutral sentiment.\" , \"neutral sentiment\"]\n",
    "\n",
    "User Feedback: {userfeedback}\n",
    "Analysis: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2508c3-c1e2-435b-8799-e7cb77323ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "UX_topic_prompt = \"\"\"\n",
    "Role: You are in the role of a UX researcher evaluting user feedback to find what users like about our system. Those likes and displikes will be eventually turned into design decisions.\n",
    "Our system is an AI system that helps user navigate a database of petroleum engineering documentation.\n",
    "\n",
    "Instructions:\n",
    "I will give you some text that is feedback from a user testing a new software system. \n",
    "This feedback may be long and cover mutliple topics. In that case break down the response into the component topics and return only 1-4 main topics.\n",
    "Also, summarize those main topics so that each one is only one or two words long, and make sure that none of the main topics are redundant.\n",
    "Think through this process step by step.\n",
    "Finally, Once you have determined a set of main topics, return those main topics in a list form like so: [\"main topic 1\", \"main topic 2\", \"main topic 3\"]. \n",
    "Do not return the users original feedback or any additional explanation.\n",
    "\n",
    "Here are two examples:\n",
    "\n",
    "Example1: \n",
    "    User Feedback: \"The search function was excellent, but the insight feature was poor\"\n",
    "    Output: [\"search function\", \"insight feature\"]\n",
    "\n",
    "Example 2:\n",
    "    User Feedback: \"The system was very difficult to use and not intuitive at all.\"\n",
    "    Output: [\"the system\"]\n",
    "\n",
    "User Feedback: {userfeedback}\n",
    "Output: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c1affd-7b7c-4b86-88d5-97834af54ea2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529e9850-a2c2-4533-b840-7ee4dcc4c681",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f471da9d-dabd-44e0-8fd8-adcd6e72c1fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab2b880-0bd1-4fd0-aedc-7922b4835584",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1fc20282-ee86-4395-8d72-0528f65e67eb",
   "metadata": {},
   "source": [
    "# Scraps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20392d15-498c-4b84-86cd-9c6ee7ac7ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUF_Df['MainTopics'] = AUF_Df['Topics'].apply(lambda x: str.split(str.split(x, 'Final Output:')[-1].strip(' []\\\"').replace('\"', '').replace(' ', ''),','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27262c9d-baf1-4539-933b-eeb0b6b941ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "str.split(str.split(AUF_Df['Topics'][2], 'Final Output:')[-1].strip(' []\\\"').replace('\"', '').replace(' ', ''),',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fae2db2-1983-4d24-b85a-1099008981a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ast.literal_eval(AUF_Df['Topics'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9424ee-5fca-40ea-8141-08cdd15d6392",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate(\n",
    "    template=UXSentiment_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9786b28a-c2a7-46f4-91dc-70675aa50e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUF_Dft3 = AUF_Df.iloc[1:3,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0872ae9b-4649-4bd7-8c6e-b255d53fce64",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUF_Dft3['Topics'] = AUF_Dft3['Message'].apply(usemistral, template=prompt_templateT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad89f1fb-fa66-4372-bcde-df5af41d5560",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUF_Dft3['Topics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1104139-375b-4578-ab96-bd2af6d01dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "UF_Df['Analysis' ,'Valence'] = UF_Df['Message'].apply(usemistral, template=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1003274f-a845-4b1a-a225-7a97bc7073f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "UF_Df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d951dfdd-65e2-4450-bef5-0835405d84cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "UF_Df.iloc[2,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e302821-38a1-4044-a8b1-05688dc03e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "UF_Df.iloc[2,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec71b57-8b32-4e9c-953c-b8834395bcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UF_Df['Analysis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67faf053-ffd4-40c7-a2e3-bd55b08ab6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUF_Dft = AUF_Df.iloc[:1,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985d4461-572a-480b-a01c-df2452100c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUF_Dft['Analysis' ,'Valence'] = AUF_Dft['Message'].apply(usemistral, template=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1171f6ad-76df-4713-93c1-b473e17b6113",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUF_Dft.iloc[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326d5abd-7a85-4b43-9609-02af066d9e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUF_Dft.iloc[0,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d510018-10c4-4511-b1d9-d8fcbeb30080",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUF_Dft2 = AUF_Df.iloc[:2,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ab3a0c-7733-4e52-bf14-c3e6e7230c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUF_Dft2['Topics'] = AUF_Dft['Message'].apply(usemistral, template=prompt_templateT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49418ccc-1f95-4974-b44e-5b87382d9621",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUF_Dft2['Message'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af7f337-4465-4722-a133-7eb7e54f2842",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUF_Dft2['Topics'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded7ef54-19ed-42b5-b697-92d22d720df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUF_Dft2['Message'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae95f6e9-f65b-4a84-a63c-3504eaf15036",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUF_Dft2['Topics'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1181375f-2a26-4db2-b217-a34fffc10477",
   "metadata": {},
   "outputs": [],
   "source": [
    "UF_Df['Valence'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c8af67-e95b-436e-9d27-ee388b73a123",
   "metadata": {},
   "outputs": [],
   "source": [
    "UF_Df['Message'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e50b65c-e8de-4358-a708-bc2ceb59f6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "UF_Df['Message'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e0692e-6848-4b2e-af57-1c0bea23539e",
   "metadata": {},
   "outputs": [],
   "source": [
    "UF_Df['Message'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fbd76f-7e2d-4d53-a99c-a68297912375",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a344671d-7559-4571-803e-ebffe62221a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef5e6ce-a220-4620-9702-e691914675f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mistral_bot(\n",
    "    prompt_template.format(\n",
    "        userfeedback=\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668165d4-ca76-44b0-b52c-746b7a9b6e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(llm('Hello, how are you?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b19db92-659e-43b8-8b5f-4aba6e4f9797",
   "metadata": {},
   "outputs": [],
   "source": [
    "teststore = llm(\"say testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d38cfca-536b-464d-a050-5f323b1d1232",
   "metadata": {},
   "outputs": [],
   "source": [
    "mistral_bot = Ollama(base_url='http://localhost:11434',\n",
    "             model=\"mistral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6cbd82-2fac-4b6c-80fb-48766a88c7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mistral_bot(\"say I am mistral\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1514bb4a-0241-4218-8505-d4a7fc675bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mistral_bot({\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"why is the sky blue?\"\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97fcbb3-9239-4db1-8b68-6d766a903c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Answer the question based on the context below. If the\n",
    "question cannot be answered using the information provided answer\n",
    "with \"I don't know\".\n",
    "\n",
    "Context: {previous_context}\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Answer: \"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"query\",\"previous_context\"],\n",
    "    template=template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342c9149-6930-49d5-b79f-16c9706e4e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    prompt_template.format(\n",
    "        query=\"Who was the first president of the united states?\",\n",
    "        previous_context=\"\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486e1026-619a-4fce-8bde-d27280cdb856",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66890773-5ed5-4298-b9b9-532039eb80a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "myquery = \"Who was the first president of the united states?\"\n",
    "current_response = mistral_bot(\n",
    "    prompt_template.format(\n",
    "        query=myquery,\n",
    "        previous_context = chat_history\n",
    "        \n",
    "    )\n",
    ")\n",
    "chat_history += \"User Question:\" + myquery + \"\\n\"\n",
    "chat_history += \"LLM Response:\" + current_response + \"\\n\"\n",
    "print(current_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d02dfc-1a88-4c32-a571-534e2f717321",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    prompt_template.format(\n",
    "        query=\"Did he write lord of the rings?\",\n",
    "        previous_context=chat_history\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66b45cb-4572-4b32-8c5f-584286f5cdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "myquery = \"What dog was in the sandlot movie?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbaba49a-8bfe-46b1-8741-9afb3a0ce53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    prompt_template.format(\n",
    "        query=\"myquery\",\n",
    "        previous_context=chat_history\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c6ebb9-067f-47ff-9e60-a6368f159386",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(chat_history) > 3000:\n",
    "    print(\"youre are running out of tokens, just a heads up.\")\n",
    "current_response = mistral_bot(\n",
    "    prompt_template.format(\n",
    "        query=myquery,\n",
    "        previous_context = chat_history\n",
    "        \n",
    "    )\n",
    ")\n",
    "chat_history += myquery\n",
    "chat_history += current_response\n",
    "print(current_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b298f1-02c7-4368-b61d-3eb165ccf5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# myquery = input()\n",
    "# if len(chat_history) > 3000:\n",
    "#     print(\"youre are running out of tokens, just a heads up.\")\n",
    "# current_response = mistral_bot(\n",
    "#     prompt_template.format(\n",
    "#         query=myquery,\n",
    "#         previous_context = chat_history\n",
    "        \n",
    "#     )\n",
    "# )\n",
    "# chat_history += myquery\n",
    "# chat_history += current_response\n",
    "# print(current_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6f41d2-b486-4d27-a91c-f4248956541b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLd User sent template\n",
    "#UXSentiment_template = \"\"\"I will give you some text that is feedback from a user testing a new software system. \n",
    "# Analyze the emotional valence expressed in the user feedback and then classify the user feedback based on the emotional valence of the text into 1 of 4 categories:\n",
    "# \"positive valence\", \"negative valence\", \"neutral valence\", or of \"mixed valence\". \n",
    "# If the text seems like it was not about the software then say simply say \"NA\". \n",
    "# first write your analysis, then classify the text, and then combine the two into a single list like so: [Analysis, Classification].\n",
    "# Below are some examples to help you.\n",
    "\n",
    "# Example 1: \n",
    "#     User Feedback: \"The search function was excellent, but the insight feature was poor\"\n",
    "#     Output:[\"the user like the search function but did not like the input function, and seemd to be equally stongly opinionated on both so this statement is of mixed valence\", \"mixed valence\"]\n",
    "#     Analysis: \"mixed valence\"\n",
    "\n",
    "# Example 2:\n",
    "#     User Feedback: \"I really liked the layout of the user interface. The software was fast and responsive, and the fucntions did exactly what I expected.\"\n",
    "#     Analysis: \"positive valence\"\n",
    "\n",
    "# Example 3:\n",
    "#     User Feedback: \"The system was very difficult to use and not intuitive at all.\"\n",
    "#     Analysis: \"negative valence\"\n",
    "\n",
    "# Example 4:\n",
    "#     User Feedback: \"I like cookies.\"\n",
    "#     Analysis: \"NA\"\n",
    "\n",
    "# Example 5:\n",
    "#     User Feedback: \"The software was fine and I finished my work.\"\n",
    "#     Analysis: \"neutral valence\"\n",
    "\n",
    "# User Feedback: {userfeedback}\n",
    "# Analysis: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3b117d-bb98-47d2-aba0-3ac84bb3cb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UserID = []\n",
    "# System = []\n",
    "# Message = []\n",
    "\n",
    "# for i in range(0,len(filelines)):\n",
    "#     if filelines[i] == '':\n",
    "#         continue\n",
    "#     elif filelines[i][-8:] == 'GMT 2023' :\n",
    "#         UserID.append(int(filelines[i].split(' ')[0].split('-')[1]))\n",
    "#         System.append(filelines[i].split(' ')[2][0])\n",
    "#     else:\n",
    "#         Message.append(filelines[i])\n",
    "        \n",
    "                      \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938478f8-f5c3-4b3b-8e4b-98f3fc0d7d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ux sentiment template 2\n",
    "# UXSentiment_template = \"\"\"I will give you some text that is feedback from a user testing a new software system. \n",
    "# Analyze the emotional valence expressed in the user feedback and then classify the user feedback based on the emotional valence of the text into 1 of 4 categories:\n",
    "# \"positive valence\", \"negative valence\", \"neutral valence\", or \"mixed valence\". \n",
    "# If the text seems like it was not about the software then say simply say \"NA\". \n",
    "# first write your analysis, then classify the text, and then combine the two into a single list like so: [Analysis, Classification].\n",
    "# Below are some examples to help you.\n",
    "\n",
    "# Example 1: \n",
    "#     User Feedback: \"The search function was excellent, but the insight feature was poor\"\n",
    "#     Output:[\"the user like the search function but did not like the input function, and seemd to be equally stongly opinionated on both so this statement is of mixed valence\" , \"mixed valence\"]\n",
    "\n",
    "# Example 2:\n",
    "#     User Feedback: \"I really liked the layout of the user interface. The software was fast and responsive, and the fucntions did exactly what I expected.\"\n",
    "#     Output: [\"The user expressed positive sentiment about all of the things they mentioned. this statement is postively valenced\" , \"positive valence\"]\n",
    "\n",
    "# Example 3:\n",
    "#     User Feedback: \"The system was very difficult to use and not intuitive at all.\"\n",
    "#     Output: [\"The user described the system as ndifficult and not intuitive. This statement is negatively valenced.\" , \"negative valence\"]\n",
    "\n",
    "# Example 4:\n",
    "#     User Feedback: \"I like ice cream.\"\n",
    "#     Analysis: [\"The statement does not seem to be about the software system.\" , \"NA\"]\n",
    "\n",
    "# Example 5:\n",
    "#     User Feedback: \"The software was fine and I finished my work.\"\n",
    "#     Analysis: [\"The user did not express any strong sentiments about the system. This statement is of neutral valence.\" , \"neutral valence\"]\n",
    "\n",
    "# User Feedback: {userfeedback}\n",
    "# Analysis: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cd80ab-68d8-4979-8734-1568ec9ef17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "UF_Df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455dd75d-e798-451c-86e5-e231af056adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "UserID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f80a65-6289-4ed0-ad81-b9f67618bd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,15):\n",
    "    if i % 3 == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401f2e3e-9640-45e2-b1d8-316268f21a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "UserID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a514e0b7-355a-4bb6-aa90-f9574fc531a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "filelines[0].split(' ')[0].split('-')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5295c94b-0aae-4a59-a133-eaf2d10f8c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filelines[0].split(' ')[2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c024c64d-5df4-47cb-a3b5-dc5661b99096",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c012fa4f-062d-4f4b-8da0-8007758f2d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()\n",
    "# dir_path = os.path.dirname(os.path.realpath(__file__))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898461c2-6bee-4773-881a-70683f32c269",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = os.path.dirname(os.path.realpath(\"FAKE_AthenUserFeedback.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a129d1f-22b4-4c07-ae25-e02c84a572ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.load(\"Downloads/FAKE_AthenUserFeedback.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4f0f28-2648-498a-b761-f585306478a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening JSON file\n",
    "f = open('Downloads/FAKE_AthenUserFeedback.txt')\n",
    " \n",
    "# returns JSON object as \n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    " \n",
    "# Iterating through the json\n",
    "# list\n",
    "for i in data['emp_details']:\n",
    "    print(i)\n",
    " \n",
    "# Closing file\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1fc567-efa5-450e-9d54-ff4a52f6b9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# FormLLM_Template = \"\"\"\n",
    "\n",
    "# Instructions: {}\n",
    "\n",
    "# Context: {}\n",
    "\n",
    "# User Input: {}\n",
    "\n",
    "# Output: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a24ef1b-78c5-43f8-9efd-d5a42933d97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TwoKilo_Template = \"\"\"\n",
    "\n",
    "# Instructions: {\n",
    "# You are a form checker, your job is to ...\n",
    "# Here are the instructions for how to fill out a 2 Kilo form. \n",
    "# Here are detail about how the information in the for is used.\n",
    "\n",
    "# Here are some examples of good an bad responses to certain fields of the 2 kilo form\n",
    "\n",
    "# Example1\n",
    "\n",
    "# Example 2\n",
    "\n",
    "# Example 3\n",
    "# }\n",
    "\n",
    "# Context: {Here is information about the role that the current sailor serves,\n",
    "# Here is infromatoin about the ship and systems that they work on, and \n",
    "# Here is infromatino about the jargon or slang associated with that role\n",
    "# Here is the infromation the sailor has already put into the form}\n",
    "\n",
    "# User Input: {The field the user is currently filling is ...\n",
    "\n",
    "# here is the users input to the field\n",
    "# }\n",
    "\n",
    "# Output: \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
